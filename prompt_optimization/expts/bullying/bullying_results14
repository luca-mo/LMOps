{"task": "ethos", "data_dir": "data/ethos", "prompts": "prompts/ethos.md", "out": "expts/bullying_results14", "max_threads": 8, "temperature": 0.0, "optimizer": "nl-gradient", "rounds": 6, "beam_size": 4, "n_test_exs": 400, "minibatch_size": 64, "n_gradients": 4, "errors_per_gradient": 4, "gradients_per_error": 1, "steps_per_gradient": 1, "mc_samples_per_step": 2, "max_expansion_factor": 8, "engine": "chatgpt", "evaluator": "ucb", "scorer": "01", "eval_rounds": 8, "eval_prompts_per_round": 8, "samples_per_eval": 32, "c": 1.0, "knn_k": 2, "knn_t": 0.993, "reject_on_errors": false, "eval_budget": 2048}
======== ROUND 0
5.3882598876953125e-05
('# Task\nIs the following text hate cyberbullying?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:',)
(1.0,)
[0.89]
======== ROUND 1
130.18887400627136
('# Task\nIs the following text promoting hatred or cyberbullying towards a specific individual or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes the text contain harmful language or behavior towards a person or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes the text promote hate or cyberbullying?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes the following text encourage hatred or cyberbullying towards a particular individual or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(0.95703125, 0.95703125, 0.94921875, 0.9419642857142857)
[0.91, 0.91, 0.915, 0.925]
======== ROUND 2
201.7666609287262
('# Task\nIs there language or behavior in the text that encourages discrimination or harm towards a particular group of individuals?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there any offensive language or threats directed towards a particular group or individual in the text?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there any offensive language or derogatory comments towards a particular gender, race, or group in the text?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there any harmful language or behavior directed towards a person or group in the text?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(0.984375, 0.984375, 0.984375, 0.984375)
[0.93, 0.92, 0.91, 0.905]
======== ROUND 3
206.69920086860657
('# Task\nIs there any offensive language or threats directed towards a particular group or individual in the text?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there language or behavior in the text that encourages discrimination or harm towards a particular group of individuals?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there any offensive language or slurs targeting a particular individual or group in the text?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there any offensive language or derogatory comments towards a particular gender, race, or group in the text?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(0.984375, 0.9791666666666666, 0.96875, 0.96875)
[0.92, 0.925, 0.925, 0.915]
======== ROUND 4
211.21309304237366
('# Task\nDoes the text contain any language or behavior that promotes discrimination or harm against a specific group of people?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes the text contain any derogatory remarks or discriminatory language towards a specific group or individual?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nAre there any instances of offensive language or threats targeting a specific group or individual in the text?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nAre there any derogatory comments or offensive language in the text that is directed towards a particular gender, race, or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(0.96875, 0.9375, 0.9375, 0.9375)
[0.935, 0.905, 0.91, 0.925]
======== ROUND 5
605.5088980197906
('# Task\nIs there any offensive language or derogatory comments directed towards a particular group, such as gender, race, religion, nationality, or ability, in the text?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes the text contain any language that could be considered discriminatory or offensive towards any group of people?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes the text contain any language that could be considered derogatory or discriminatory towards a particular group or individual?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes the text contain language or behavior that promotes discrimination, harm, violence, or abuse against any group of people or individuals?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(1.0, 1.0, 1.0, 0.984375)
[0.915, 0.91, 0.92, 0.94]
======== ROUND 6
227.7839560508728
('# Task\nIs there any language in the text that could be viewed as derogatory or discriminatory towards a specific group or individual?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes the text contain language or behavior that dehumanizes, belittles, or incites harm towards specific individuals or groups based on their race, gender, ethnicity, sexual orientation, religion, or other characteristics?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes the text contain any language that could be considered discriminatory or offensive towards any group of people?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there language or behavior in the text that dehumanizes, belittles, or encourages harm towards certain individuals or groups due to their race, gender, ethnicity, sexual orientation, religion, or other characteristics?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(0.984375, 0.984375, 0.984375, 0.96875)
[0.895, 0.945, 0.91, 0.925]
