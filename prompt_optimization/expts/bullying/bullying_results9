{"task": "bullying", "data_dir": "data/bullying", "prompts": "prompts/bullying2.md", "out": "expts/bullying_results9", "max_threads": 8, "temperature": 0.0, "optimizer": "nl-gradient", "rounds": 6, "beam_size": 4, "n_test_exs": 400, "minibatch_size": 64, "n_gradients": 4, "errors_per_gradient": 4, "gradients_per_error": 1, "steps_per_gradient": 1, "mc_samples_per_step": 2, "max_expansion_factor": 8, "engine": "chatgpt", "evaluator": "ucb", "scorer": "01", "eval_rounds": 8, "eval_prompts_per_round": 8, "samples_per_eval": 32, "c": 1.0, "knn_k": 2, "knn_t": 0.993, "reject_on_errors": false, "eval_budget": 2048}
======== ROUND 0
5.4836273193359375e-05
('# Task\nDoes this tweet intend to harm or humiliate someone through its content?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:',)
(1.0,)
[0.6375]
======== ROUND 1
143.8567337989807
('# Task\nIs the language in this tweet disrespectful or offensive to a particular individual or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs the language in this tweet derogatory, offensive, or intended to belittle or harm someone?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes this tweet contain language or content that could be interpreted as harmful or humiliating towards someone?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes the language used in this tweet aim to be derogatory, offensive, or to belittle or harm someone?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(0.734375, 0.734375, 0.72265625, 0.71875)
[0.69, 0.68, 0.6725, 0.6925]
======== ROUND 2
253.06379389762878
('# Task\nIs there any language or content in this tweet that may be seen as harmful or humiliating towards someone?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there any derogatory or harmful language towards a specific individual or group in the language used in this tweet?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs the language in this tweet intended to belittle, offend, or cause harm to someone with ill intentions?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs the language in this tweet using derogatory language or slurs towards a specific individual or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(0.75, 0.75, 0.7395833333333334, 0.734375)
[0.68, 0.6975, 0.695, 0.6525]
======== ROUND 3
235.21902203559875
('# Task\nIs the language in this tweet displaying any form of negativity, bullying, or harmful behavior towards a specific individual or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there language in the text that could be harmful or offensive to others?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there language in the text that is derogatory, offensive, or harmful towards a particular group or individual?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes the language used in this tweet contain any negativity, bullying, or harmful behavior towards a specific individual or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(0.7604166666666666, 0.7395833333333334, 0.734375, 0.734375)
[0.695, 0.6675, 0.6875, 0.6975]
======== ROUND 4
243.54142785072327
('# Task\nIs there language in the text that is disrespectful, hurtful, or discriminatory towards a specific group or individual?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there any indication of negative sentiment, harassment, or harmful behavior towards a particular individual or group in the language used in this text?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there any explicit language, hate speech, or derogatory remarks towards a specific group of people in the text?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes the language used in this tweet show any signs of negativity, bullying, or harmful behavior towards a particular individual or group, regardless of the situation?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(0.78125, 0.75, 0.75, 0.75)
[0.6875, 0.685, 0.6675, 0.6975]
======== ROUND 5
205.23946475982666
('# Task\nIs there derogatory language or slurs in the text that target a specific group or individual?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there any offensive language, harmful stereotypes, or discriminatory remarks towards any group of individuals in the text?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there any language in the text that is deliberately harmful, offensive, or discriminatory towards a particular group of individuals?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there any language in this text that could be seen as derogatory, harmful, or discriminatory towards a specific individual or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(0.75, 0.75, 0.7395833333333334, 0.7291666666666666)
[0.645, 0.6825, 0.69, 0.6875]
======== ROUND 6
193.85407781600952
('# Task\nIs there language in the text that could be harmful, offensive, or discriminatory towards any group of individuals, whether it is explicit or implicit?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there any language or behavior in the text that may be harmful, offensive, or disrespectful to others?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there any language in the text that is discriminatory or harmful towards any group or individual?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there any language in the text that discriminates against or harms any group or individual?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(0.75, 0.75, 0.75, 0.7395833333333334)
[0.6925, 0.6925, 0.6975, 0.69]
