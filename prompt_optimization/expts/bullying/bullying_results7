{"task": "bullying", "data_dir": "data/bullying", "prompts": "prompts/bullying1.md", "out": "expts/bullying_results7", "max_threads": 8, "temperature": 0.0, "optimizer": "nl-gradient", "rounds": 6, "beam_size": 4, "n_test_exs": 400, "minibatch_size": 64, "n_gradients": 4, "errors_per_gradient": 4, "gradients_per_error": 1, "steps_per_gradient": 1, "mc_samples_per_step": 2, "max_expansion_factor": 8, "engine": "chatgpt", "evaluator": "ucb", "scorer": "01", "eval_rounds": 8, "eval_prompts_per_round": 8, "samples_per_eval": 32, "c": 1.0, "knn_k": 2, "knn_t": 0.993, "reject_on_errors": false, "eval_budget": 2048}
======== ROUND 0
9.107589721679688e-05
('# Task\nIs this tweet cyberbullying?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:',)
(1.0,)
[0.6625]
======== ROUND 1
142.1641399860382
('# Task\nIs there any harmful or offensive language in this tweet that is directed towards an individual or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes this tweet contain harmful or offensive language towards an individual or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes this tweet contain harmful or offensive language directed towards an individual or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there targeted harassment or abusive language towards an individual or group in this tweet?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(0.6796875, 0.67578125, 0.671875, 0.66015625)
[0.685, 0.6675, 0.6675, 0.6825]
======== ROUND 2
201.18640112876892
('# Task\nIs the language in this tweet derogatory or offensive towards a specific individual or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes this tweet contain language that is intended to harm, offend, or discriminate against an individual or group based on characteristics such as race, gender, sexual orientation, or disability?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes this tweet contain harmful or offensive language directed towards an individual or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes the language used in this tweet contain derogatory, discriminatory, or harmful content targeting a particular individual or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(0.7578125, 0.75, 0.7291666666666666, 0.7291666666666666)
[0.69, 0.68, 0.6725, 0.6975]
======== ROUND 3
198.71228194236755
('# Task\nDoes this tweet use language that is derogatory or demeaning towards a particular individual or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs the language in this tweet directed towards a specific individual or group in a derogatory, discriminatory, or harmful manner?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes the language used in this tweet contain derogatory or offensive remarks targeted at a particular individual or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there language in this tweet that could reinforce harmful stereotypes or contribute to systemic biases against individuals or groups based on characteristics like race, gender, sexual orientation, or disability?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(0.8125, 0.796875, 0.796875, 0.78125)
[0.67, 0.6875, 0.6725, 0.72]
======== ROUND 4
203.23918795585632
('# Task\nDoes the language in this tweet target a particular individual or group in a derogatory, discriminatory, or harmful way, either explicitly or implicitly?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes this tweet use language that is derogatory or demeaning towards a particular individual or group?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes this tweet contain language that could perpetuate negative attitudes or discrimination towards certain groups based on race, gender, sexual orientation, or disability?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes this tweet contain language that may perpetuate harmful stereotypes or uphold systemic biases against individuals or groups due to characteristics such as race, gender, sexual orientation, or disability?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(0.71875, 0.703125, 0.703125, 0.6875)
[0.67, 0.6725, 0.6975, 0.7075]
======== ROUND 5
204.61023712158203
('# Task\nIs there any language in this tweet that is derogatory, discriminatory, or harmful towards any individual or group, whether explicitly stated or implied?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there any derogatory, discriminatory, or harmful language towards any individual or group, explicit or implied, in this tweet?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes this tweet contain language that may perpetuate harmful stereotypes or uphold systemic biases against individuals or groups based on their characteristics or personal experiences?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there language in this tweet that suggests negative stereotypes or biases towards certain groups based on race, gender, sexual orientation, or disability?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(0.78125, 0.78125, 0.78125, 0.765625)
[0.695, 0.7075, 0.7125, 0.71]
======== ROUND 6
202.08646607398987
('# Task\nDoes this tweet contain language that may perpetuate harm, whether through stereotypes, biases, bullying, exclusion, or other negative behaviors, against individuals or groups based on their characteristics or personal experiences?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nDoes this tweet contain any language that may be derogatory, discriminatory, or harmful towards any individual or group, whether explicit or implied?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there language in this tweet that suggests negative stereotypes or biases towards certain groups based on race, gender, sexual orientation, or disability?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:', '# Task\nIs there any derogatory, discriminatory, or harmful language towards any individual or group, explicit or implied, in this tweet?\n\n# Output format\nAnswer Yes or No as labels\n\n# Prediction\nText: {{ text }}\nLabel:')
(0.765625, 0.765625, 0.75, 0.75)
[0.7, 0.69, 0.715, 0.7075]
